from bioprospecting import databases
from bioprospecting import MD
from bioprospecting import alignment
from bioprospecting import structural_search
import shutil
import os
import json
import mdtraj as md
import numpy as np
import matplotlib.pyplot as plt
from multiprocessing import Pool, cpu_count
from Bio import PDB


class mutation_restrictions:

    def __init__(self, input_model, model_name, search_folder, search_software='psiblast',
                 chain=None, output_folder='mutation_restrictions', database='uniprotkb'):
        '''
        search_folder should be either the psiblast folder generated by trembl.PSIBlast() or the foldseek folder generated by foldseek.runEasySearch()
        model_name should be the name of your target in psiblast or the name of the name of the target in foldseek

        input_model : str
            Path to the input model PDB.

        '''
        self.input_model = input_model
        self.model_name = model_name
        self.search_folder = search_folder

        available_ss = ['psiblast', 'foldseek', 'blast']
        if search_software not in available_ss:
            raise ValueError('Can only read output from the following programs '+available_ss)
        self.search_software = search_software

        if search_software == 'psiblast' or search_software == 'blast':
            self.ref_seq = alignment.readFastaFile(self.search_folder+'/'+self.model_name+'/'+self.model_name+'.fasta')[self.model_name]
        elif search_software == 'foldseek':
            self.fs_df = structural_search.foldseek.parseFoldSeekOutput(search_folder)
            if chain != None:
                sel_indices = [i for i in self.fs_df.index if i.split('_')[-1] == chain and i.split('.')[0] == self.model_name]
                self.fs_df = self.fs_df[self.fs_df.index.isin(sel_indices)]
            self.ref_seq = self.fs_df['qseq'][0]

        available_db = ['uniprotkb','swissprot']
        if database not in available_db:
            raise ValueError(database +' has not been implemented yet.')
        self.database = database

        self.output_folder = output_folder
        if not os.path.exists(self.output_folder):
            os.mkdir(self.output_folder)

        if not os.path.exists(self.output_folder+'/'+self.model_name):
            os.mkdir(self.output_folder+'/'+self.model_name)

        '''
        self.allowed_aa = {}
        for file in os.listdir(self.output_folder):
            if file.startswith('allowed_aa'):
                with open(self.output_folder+'/'+file) as f:
                    self.allowed_aa[file.split('_')[1].replace('.json','')] = json.load(f)
        '''

        if os.path.exists(self.output_folder+'/'+self.model_name+'/scores.json'):
            with open(self.output_folder+'/'+self.model_name+'/scores.json') as f:
                self.scores = json.load(f)
        else:
            self.scores = {}

        if os.path.exists(self.output_folder+'/'+self.model_name+'/counts.json'):
            with open(self.output_folder+'/'+self.model_name+'/counts.json') as f:
                self.counts = json.load(f)
        else:
            self.counts = {}

    def getMutablePositions(self,cov_filter=0.75, id_filter=0.35, tm_score_filter=0.5, scores_threshold=None, max_seqs=None,
                            return_all_counts=False, overwrite=False, cpus=None, return_counts=False, verbose=True, rosetta_params=None,
                            return_seq=False):

        """

        Returns the possible mutations on each position of the protein based on the multiple sequence alignment of a psiblast search.
        #### TODO ####
        # Add second msa after coverage and identity filter
        # Structural alignment only of regions that are not loops
        # Consider different databases (trembl)
        # Consider PSIBLAST/BLAST

        # fireprot (codon information)
        # Consider blosum for synonim mutations, consider amino acid groups
        # build phylogenetic tree to check mutations that occur in group
        # tcofee instead of clustalw
        ####

        Parameters
        ==========
        input_model : str
            Path to the input model PDB.
        model_name : str
            Name of the model. (The one you gave it in the PSIBLAST search)
        search_folder : str
            Folder where psiblast was run.
        Returns
        =======
        mut_pos : dict
            Dictionary of the possible aa to mutate in each position.
        """
        # Define target structure
        #parser = PDB.PDBParser()
        #ref_struct =  parser.get_structure('ref',input_model)
        #ref_seq = ''.join([three_to_one(i.resname) for i in ref_struct.get_residues() if i.id[0] == ' '])
        #ref_seq = alignment.readFastaFile(search_folder+'/'+model_name+'/'+model_name+'.fasta')[model_name]


        if  self.counts == {} or overwrite:
            # Check if pyrosetta is installed
            try:
                import pyrosetta
                if rosetta_params != None:
                    pyrosetta.init('-extra_res_path '+rosetta_params)
                else:
                    pyrosetta.init()

            except ImportError as e:
                raise ValueError('pyrosetta python module not avaiable. Please install it to use this function.')

            # Get secondary structure of target and defined loop ranges
            pose = pyrosetta.pose_from_pdb(self.input_model)
            DSSP = pyrosetta.rosetta.protocols.moves.DsspMover()
            DSSP.apply(pose)
            ss = pose.secstruct()

            loop_ranges = []
            in_loop = False
            for i,p in enumerate(ss):
                if p == 'L' and not in_loop:
                    in_loop = True
                    loop = []
                    loop.append(i)
                elif p == 'L' and in_loop:
                    loop.append(i)
                elif p != 'L' and in_loop:
                    loop_ranges.append(loop)
                    in_loop = False

            if self.search_software == 'psiblast' or self.search_software == 'blast':

                # Get sequences of hits obtained with psiblast
                if self.search_software == 'psiblast':
                    codes = databases.trembl.readPSIBLASTResults(self.search_folder, as_one_bundle=True, only_codes=True)
                if self.search_software == 'blast':
                    codes = databases.trembl.readBLASTResults(self.search_folder, only_codes=True)

                if max_seqs != None:
                    codes = codes[0:max_seqs]

                upd = databases.uniprot(codes[self.model_name], database=self.database)
                upd.getFastaFiles()
                upd.parseFastas()
                target = {'target':self.ref_seq}
                seqs = target | upd.sequences

            elif self.search_software == 'foldseek':
                target = {'target':self.ref_seq}
                if max_seqs != None:
                    seqs = target | dict(zip(list(self.fs_df['target'])[0:max_seqs],list(self.fs_df['tseq'])[0:max_seqs]))
                else:
                    seqs = target | dict(zip(list(self.fs_df['target']),list(self.fs_df['tseq'])))

            if verbose:
                print('Running multiple sequence alignment for '+str(len(seqs))+' proteins')

            # Modify length of target identifier because for some reason cdhit does not accept ones larger than 19
            new_seqs = {}
            for k in seqs:
                if len(k) > 19:
                    new_seqs[k[0:18]] = seqs[k]
                else:
                    new_seqs[k] = seqs[k]
            seqs = new_seqs


            msa = alignment.mafft.multipleSequenceAlignment(seqs,stderr=False)

            if verbose:
                print('Multiple sequence alignment finished. Checking sequence identity and coverage.')

            # Filter by coverage and sequence identity
            if self.search_software == 'psiblast' or self.search_software == 'blast':
                target_seq = msa[0].seq
                codes_to_remove = []
                low_id = []
                for s in msa:
                    coverage = 0
                    identity = 0
                    for i,r in enumerate(s.seq):
                        if target_seq[i] != '-' and r != '-':
                            coverage += 1
                        if target_seq[i] == r and r != '-':
                            identity += 1
                    if coverage/len(self.ref_seq) < cov_filter:
                        codes_to_remove.append(s.id)
                    elif identity/len(self.ref_seq) < id_filter:
                        low_id.append(s.id)


                if verbose:
                    print(str(len(codes_to_remove))+' sequences found with low coverage.')
                    print(str(len(low_id))+' sequences found with low identity. Donwloading alphafold to check structural similarity.')

                for code in low_id:
                    databases.retrieveAlphaFoldStructure(code,self.output_folder+'/'+self.model_name+'/psiblast_alphafold_struct')

                # Check if any filtered codes can be saved by structural alignment
                saved_codes = []
                rmsd = {}

                align_data = {}

                if not os.path.exists(self.output_folder+'/'+self.model_name+'/af_aligned_data'):
                    os.mkdir(self.output_folder+'/'+self.model_name+'/af_aligned_data')

                for file in os.listdir(self.output_folder+'/'+self.model_name+'/af_aligned_data'):
                    if os.stat(self.output_folder+'/'+self.model_name+'/af_aligned_data/'+file).st_size != 0:
                        for l in open(self.output_folder+'/'+self.model_name+'/af_aligned_data/'+file):
                            if l.startswith('TM-score='):
                                score = l.split()[1]
                                break
                        align_data[file.replace('.txt','')] = float(score)

                jobs = []
                for model in os.listdir(self.output_folder+'/'+self.model_name+'/psiblast_alphafold_struct'):
                    if model.endswith('.pdb') and model.split('-')[1].replace('.pdb','') in low_id and model.replace('.pdb','') not in align_data:
                        jobs.append((self.output_folder+'/'+self.model_name+'/psiblast_alphafold_struct/'+model,self.input_model))

                if cpus == None:
                    cpus = cpu_count()
                pool = Pool(cpus)
                pool.map(self.afAlign, jobs)

                for file in os.listdir(self.output_folder+'/'+self.model_name+'/af_aligned_data'):
                    for l in open(self.output_folder+'/'+self.model_name+'/af_aligned_data/'+file):
                        if l.startswith('TM-score='):
                            score = l.split()[1]
                            break
                    align_data[file.replace('.txt','')] = float(score)

                for c in align_data:
                    if align_data[c] >= tm_score_filter:
                        saved_codes.append(c.split('-')[1].replace('.pdb',''))

                if verbose:
                    print(str(len(saved_codes))+' proteins had high structural similarity and will be considered')

                codes_to_remove += [c for c in low_id if c not in saved_codes]
            elif self.search_software == 'foldseek':
                print('Since foldseek has been used to search homologues asume that coverage and sequence identity filters are not necessary.')
                codes_to_remove = []

            # Give weight to each of the sequences in the alignment based on their similarity
            seqs = {k:v for k,v in seqs.items() if k not in codes_to_remove}
            if return_seq:
                return seqs
            if verbose:
                print('Calculating sequences clusters.')
            cluster = alignment.cdhit.clusterSequences(seqs)
            weights = {}
            for c in cluster.values():
                for m in c:
                    weights[m] = 1/len(c)

            # Get msa position of loop regions
            if verbose:
                print('Get msa position of loop regions.')
            msa_loop_ranges = []
            for r in loop_ranges:
                r = [x+1 for x in r]
                msa_loop_ranges.append(alignment.getMsaIndexesFromSequencePositions(msa,'target',r))

            # Get loop regions that have gaps in them
            if verbose:
                print('Get loop regions that have gaps in them.')
            t_sequence = msa[0].seq
            gapped_loop = {}
            for s in msa:
                gapped_loop[s.id] = []
                for j,rng in enumerate(msa_loop_ranges):
                    for pos in rng:
                        if (t_sequence[pos] != '-') ^ (s.seq[pos] != '-'):
                            gapped_loop[s.id].append(j)
                            break

            # Get counts
            count = {}
            print('Calculating counts.')
            all_loop_pos = [item for sublist in msa_loop_ranges for item in sublist]
            t_sequence = msa[0].seq
            in_loop = False
            allowed_aa = {}
            for i in range(msa.get_alignment_length()):
                in_loop = False
                if i in all_loop_pos:
                    in_loop = True
                    for j,rng in enumerate(msa_loop_ranges):
                        if i in rng:
                            loop_range = j
                            break
                for s in msa:
                    if s.id not in codes_to_remove:
                        count.setdefault(s.id, 0)
                        if s.seq[i] != '-':
                            count[s.id] += 1
                        if t_sequence[i] != '-':
                            position = count['target']
                            allowed_aa.setdefault(position, {})
                            if in_loop:
                                if loop_range not in gapped_loop[s.id]:
                                    allowed_aa[position].setdefault(s.seq[i], 0)
                                    allowed_aa[position][s.seq[i]] += 1*weights[s.id]
                            else:
                                allowed_aa[position].setdefault(s.seq[i], 0)
                                allowed_aa[position][s.seq[i]] += 1*weights[s.id]

            self.counts = allowed_aa
            if verbose:
                print('Calculating counts finished.')
            with open(self.output_folder+'/'+self.model_name+'/'+'counts.json','w') as f:
                json.dump(self.counts,f)

        if return_all_counts:
            all_counts = {}
            for pos in self.counts:
                all_counts[pos] = [k for k,v in self.counts.items() if v > 0]

            return all_counts

        elif return_counts:
            return self.counts
        
        else:
            print("Calculating scores.")
            if self.scores != {} and not overwrite:
                if scores_threshold == None:
                    return self.scores
                else:
                    return self.get_mutable_pos_from_score(scores_threshold)
            else:
                if scores_threshold == None:
                    self.get_scores_from_count()
                    return self.scores
                else:
                    self.get_scores_from_count()
                    return self.get_mutable_pos_from_score(scores_threshold)

                    #return self.allowed_aa[scores_threshold]

    def get_scores_from_count(self):

        # Background frequencies of aa
        data = {}
        # source: https://www.ebi.ac.uk/uniprot/TrEMBLstats
        data['uniprotkb'] = {
            'A': 0.0905,
            'Q': 0.0380,
            'L': 0.0987,
            'S': 0.0678,
            'R': 0.0584,
            'E': 0.0624,
            'K': 0.0493,
            'T': 0.0554,
            'N': 0.0379,
            'G': 0.0728,
            'M': 0.0233,
            'W': 0.0130,
            'D': 0.0547,
            'H': 0.0221,
            'F': 0.0389,
            'Y': 0.0288,
            'C': 0.0128,
            'I': 0.0555,
            'P': 0.0498,
            'V': 0.0688
            }
        # source: https://web.expasy.org/docs/relnotes/relstat.html
        data['swissprot'] = {
            'A': 0.0825,
            'Q': 0.0393,
            'L': 0.0965,
            'S': 0.0665,
            'R': 0.0553,
            'E': 0.0672,
            'K': 0.0580,
            'T': 0.0536,
            'N': 0.0406,
            'G': 0.0707,
            'M': 0.0241,
            'W': 0.0110,
            'D': 0.0546,
            'H': 0.0227,
            'F': 0.0386,
            'Y': 0.0292,
            'C': 0.0138,
            'I': 0.0591,
            'P': 0.0474,
            'V': 0.0685
            }

        background_frequencies = data[self.database]

        # Calculate frequencies
        frequencies = {}
        for pos in self.counts:
            frequencies[pos] = {}
            for aa in self.counts[pos]:
                if aa != '-' and aa != 'Z' and aa != 'X':
                    frequencies[pos][aa] = self.counts[pos][aa]/sum(self.counts[pos].values())

        # Calculate log scores
        scores = {}
        for pos in frequencies:
            scores[pos] = {}
            for aa in frequencies[pos]:
                scores[pos][aa] = np.log(frequencies[pos][aa]/background_frequencies[aa])

        self.scores = scores

        with open(self.output_folder+'/'+self.model_name+'/'+'scores.json','w') as f:
            json.dump(self.scores,f)

    def get_mutable_pos_from_score(self,scores_threshold):

        # Get mutable positions from scores
        mut_pos = {}
        for pos in self.scores:
            mut_pos[pos] = []
            for aa in self.scores[pos]:
                if self.scores[pos][aa] > scores_threshold:
                    mut_pos[pos].append(aa)
            native_aa = self.ref_seq[int(pos)-1]
            if native_aa not in mut_pos[pos]:
                mut_pos[pos].append(native_aa)

        parser = PDB.PDBParser()
        struct = parser.get_structure('input',self.input_model)
        new_mut_pos = {}
        for i,r in enumerate(struct.get_residues()):
            if (i+1) in mut_pos:
                new_mut_pos[r.full_id[3][1]] = mut_pos[i+1]

        return mut_pos
        #with open(self.output_folder+'/'+'allowed_aa_'+str(scores_threshold).replace('.',',')+'.json','w') as f:
        #    json.dump(self.allowed_aa[scores_threshold],f)

    def getMutationsScores(self, mut_seq, positions=None):
        """

        Get the sum of the scores for a mutated sequence.

        Parameters
        ==========
        mut_seq : str
            Sequence with the mutations.
        positions : list
            List with the positions to consider for the score. If is None all mutations will be considered.

        Returns
        =======
        score : float
            Sum of all scores for given mutated positions.
        """

        if self.scores == {} and  self.counts == {}:
            raise ValueError('There are no scores or counts calculated. Run getMutablePositions first.')
        elif self.counts != {}:
            self.get_scores_from_count()

        score = 0

        for i in range(len(self.ref_seq)):
            if seq[i] != native_seq[i]:
                if positions != None:
                    if i+1 in self.scores:
                        score += self.scores[i+1][seq[i]]
                    else:
                        score = -np.inf
                else:
                    if (i+1) in positions:
                        if i+1 in self.scores:
                            score += self.scores[i+1][seq[i]]
                        else:
                            score = -np.inf

        return score



    def plotThresholds(self,max_range=7,min_range=-7,step=0.05,vlines=[0.5]):

        avg_counts = []
        thresholds = np.arange(min_range, max_range+0.1, step)
        for i in thresholds:

            if self.scores != {}:
                mutatable_positions = self.get_mutable_pos_from_score(i)
            elif self.counts != {}:
                self.get_scores_from_count()
                mutatable_positions = self.get_mutable_pos_from_score(i)
            else:
                raise ValueError('There are no scores or counts calculated. Run getMutablePositions first.')

            max_count = []
            for pos in mutatable_positions:
                max_count.append(len(mutatable_positions[pos]))
            avg_counts.append(np.average(max_count))

        plt.plot(thresholds, avg_counts, c='k')
        plt.ylabel('Average number of allowed mutations')
        plt.xlabel('Relative entropy threshold')
        nmut_range = max(avg_counts)-min(avg_counts)

        if 0.5 not in vlines:
            vlines.append(0.5)

        threshold_values = {}

        for i in vlines:
            l_value = (nmut_range*i)+min(avg_counts)
            l_point = thresholds[np.argmin([np.abs(x-l_value) for x in avg_counts])]

            threshold_values[i] = l_point

            if i == 0.5:
                plt.axhline(l_value, ls='--', c='k')
                plt.axvline(l_point, ls='--', c='k')
            else:
                plt.axvline(l_point, ls='--', c='r')

        return threshold_values

    def afAlign(self,data):
        model = data[0]
        reference = data[1]
        os.system('TMalign '+reference+' '+model+' >> '+self.output_folder+'/'+self.model_name+'/af_aligned_data/'+model.split('/')[-1].replace('.pdb','.txt'))
